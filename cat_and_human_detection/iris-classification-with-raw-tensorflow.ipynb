{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf  # tensorflow \n",
    "import numpy as np       ## numpy packages\n",
    "from sklearn.model_selection import cross_val_score  ## for cross validation\n",
    "from sklearn.preprocessing import OneHotEncoder    #3 for encoding\n",
    "from sklearn.utils import shuffle  ## shiffle the data\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import logging ## for logging the data\n",
    "from sklearn import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "## load the dataaet\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fetching the feature matrix and the target\n",
    "X = np.asarray(iris.data,'float32')\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:172: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:189: UserWarning: Numerical issues were encountered when scaling the data and might not be solved. The standard deviation of the data is probably very close to 0. \n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "## preproces the data\n",
    "X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = min_max_scaler.fit_transform(X) ## this is actually normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert to binary\n",
    "lb = preprocessing.LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = lb.fit_transform(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 1 0]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]\n",
      " [0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "##train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1388889  0.5833334  0.15254238 0.0416666 ]\n",
      " [0.30555555 0.79166675 0.05084744 0.12499997]\n",
      " [0.11111102 0.50000006 0.05084744 0.0416666 ]\n",
      " [0.41666672 0.24999997 0.5084746  0.4583333 ]\n",
      " [0.8055555  0.4166667  0.8135593  0.625     ]\n",
      " [0.1944444  0.6666666  0.06779659 0.0416666 ]\n",
      " [0.6666666  0.5416667  0.7966101  0.83333325]\n",
      " [0.83333343 0.37500006 0.89830506 0.70833325]\n",
      " [0.86111116 0.3333333  0.8644067  0.75      ]\n",
      " [0.6111111  0.3333333  0.6101695  0.5833333 ]\n",
      " [0.1944444  0.5416667  0.06779659 0.0416666 ]\n",
      " [0.49999997 0.3333333  0.5084746  0.49999994]\n",
      " [0.7777778  0.4166667  0.8305085  0.83333325]\n",
      " [0.4722222  0.37500006 0.59322035 0.5833333 ]\n",
      " [0.24999993 0.875      0.08474576 0.        ]\n",
      " [0.08333325 0.50000006 0.06779659 0.0416666 ]\n",
      " [0.22222216 0.5833334  0.08474576 0.0416666 ]\n",
      " [0.08333325 0.6666666  0.         0.0416666 ]\n",
      " [0.8055555  0.50000006 0.8474576  0.70833325]\n",
      " [0.69444454 0.4166667  0.7627119  0.83333325]\n",
      " [0.3333333  0.16666672 0.47457626 0.41666666]\n",
      " [0.24999993 0.625      0.08474576 0.0416666 ]\n",
      " [0.4722222  0.08333334 0.5084746  0.37499997]\n",
      " [0.41666672 0.8333334  0.03389832 0.0416666 ]\n",
      " [0.9444445  0.3333333  0.96610165 0.7916666 ]\n",
      " [0.38888884 0.3333333  0.59322035 0.49999994]\n",
      " [0.5555556  0.20833334 0.66101694 0.5833333 ]\n",
      " [0.49999997 0.24999997 0.779661   0.5416666 ]\n",
      " [0.1944444  0.         0.42372882 0.37499997]\n",
      " [0.4722222  0.5833334  0.59322035 0.625     ]\n",
      " [0.5555556  0.12499997 0.5762712  0.49999994]\n",
      " [0.1388889  0.4166667  0.06779659 0.        ]\n",
      " [0.6666666  0.20833334 0.8135593  0.70833325]\n",
      " [0.5833334  0.3333333  0.779661   0.875     ]\n",
      " [0.22222216 0.75       0.10169494 0.0416666 ]\n",
      " [0.49999997 0.4166667  0.6101695  0.5416666 ]\n",
      " [0.38888884 0.3333333  0.5254237  0.49999994]\n",
      " [0.9166667  0.4166667  0.94915247 0.83333325]\n",
      " [0.41666672 0.2916667  0.49152544 0.4583333 ]\n",
      " [0.36111107 0.2916667  0.5423728  0.49999994]\n",
      " [0.05555552 0.12499997 0.05084744 0.08333328]\n",
      " [0.1388889  0.4166667  0.06779659 0.08333328]\n",
      " [0.30555555 0.7083334  0.08474576 0.0416666 ]\n",
      " [0.24999993 0.2916667  0.49152544 0.5416666 ]\n",
      " [0.22222216 0.5416667  0.11864406 0.16666663]\n",
      " [0.69444454 0.50000006 0.8305085  0.9166666 ]\n",
      " [0.41666672 0.2916667  0.5254237  0.37499997]\n",
      " [0.5833334  0.2916667  0.7288136  0.75      ]\n",
      " [0.5555556  0.5416667  0.8474576  0.99999994]\n",
      " [0.16666666 0.6666666  0.06779659 0.        ]\n",
      " [0.8055555  0.6666666  0.8644067  0.99999994]\n",
      " [0.6666666  0.4583333  0.779661   0.9583333 ]\n",
      " [0.22222216 0.20833334 0.33898306 0.41666666]\n",
      " [0.22222216 0.625      0.06779659 0.0416666 ]\n",
      " [0.38888884 0.24999997 0.42372882 0.37499997]\n",
      " [0.1944444  0.12499997 0.3898305  0.37499997]\n",
      " [0.36111107 0.4166667  0.5254237  0.49999994]\n",
      " [0.5833334  0.37500006 0.55932206 0.49999994]\n",
      " [0.11111102 0.50000006 0.10169494 0.0416666 ]\n",
      " [0.6666666  0.4583333  0.6271186  0.5833333 ]\n",
      " [0.5833334  0.50000006 0.59322035 0.5833333 ]\n",
      " [0.16666666 0.20833334 0.59322035 0.6666666 ]\n",
      " [0.75       0.50000006 0.6271186  0.5416666 ]\n",
      " [0.6111111  0.50000006 0.69491524 0.7916666 ]\n",
      " [0.02777776 0.4166667  0.05084744 0.0416666 ]\n",
      " [0.3333333  0.24999997 0.5762712  0.4583333 ]\n",
      " [0.52777773 0.3333333  0.6440678  0.70833325]\n",
      " [0.5555556  0.2916667  0.66101694 0.70833325]\n",
      " [0.22222216 0.75       0.08474576 0.08333328]\n",
      " [0.02777776 0.37500006 0.06779659 0.0416666 ]\n",
      " [0.02777776 0.50000006 0.05084744 0.0416666 ]\n",
      " [0.4722222  0.2916667  0.69491524 0.625     ]\n",
      " [0.1944444  0.5833334  0.08474576 0.0416666 ]\n",
      " [0.41666672 0.2916667  0.69491524 0.75      ]\n",
      " [0.         0.4166667  0.01694921 0.        ]\n",
      " [0.24999993 0.5833334  0.06779659 0.0416666 ]\n",
      " [0.08333325 0.5833334  0.06779659 0.08333328]\n",
      " [0.49999997 0.37500006 0.6271186  0.5416666 ]\n",
      " [0.4722222  0.08333334 0.6779661  0.5833333 ]\n",
      " [0.30555555 0.4166667  0.59322035 0.5833333 ]\n",
      " [0.44444448 0.4166667  0.69491524 0.70833325]\n",
      " [0.72222227 0.4583333  0.7457627  0.83333325]\n",
      " [0.52777773 0.5833334  0.7457627  0.9166666 ]\n",
      " [0.22222216 0.7083334  0.08474576 0.12499997]\n",
      " [0.9444445  0.75       0.96610165 0.875     ]\n",
      " [0.36111107 0.4166667  0.59322035 0.5833333 ]\n",
      " [0.5555556  0.20833334 0.6779661  0.75      ]\n",
      " [0.1944444  0.4166667  0.10169494 0.0416666 ]\n",
      " [0.38888884 0.37500006 0.5423728  0.49999994]\n",
      " [0.6388889  0.37500006 0.6101695  0.49999994]\n",
      " [0.16666666 0.4583333  0.08474576 0.0416666 ]\n",
      " [0.3333333  0.625      0.05084744 0.0416666 ]\n",
      " [0.1388889  0.5833334  0.10169494 0.0416666 ]\n",
      " [0.44444448 0.4166667  0.5423728  0.5833333 ]\n",
      " [0.5555556  0.5833334  0.779661   0.9583333 ]\n",
      " [0.22222216 0.625      0.06779659 0.08333328]\n",
      " [0.49999997 0.4166667  0.66101694 0.70833325]\n",
      " [0.5833334  0.4583333  0.7627119  0.70833325]\n",
      " [0.52777773 0.37500006 0.55932206 0.49999994]\n",
      " [0.72222227 0.50000006 0.7966101  0.9166666 ]\n",
      " [0.6666666  0.5416667  0.7966101  0.99999994]\n",
      " [0.6111111  0.4166667  0.7627119  0.70833325]\n",
      " [0.44444448 0.50000006 0.6440678  0.70833325]\n",
      " [0.36111107 0.20833334 0.49152544 0.41666666]\n",
      " [1.         0.75       0.91525424 0.7916666 ]]\n"
     ]
    }
   ],
   "source": [
    "print (x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model creation by scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first create the placeholder\n",
    "X = tf.placeholder('float',[None,4]) ## we feed a lot of data and its dimanesion is 4\n",
    "Y = tf.placeholder('float',[None,3]) ## we feed a lot of data and its dimanesion is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## init the weight\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_h = init_weights([4,4]) ## this is the primary variable\n",
    "w_o = init_weights([4,3])  ## this is another layer and this is the \n",
    "## final layer so thats why it has 4 input and output 3 cause the target is 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X,w_h,w_o):\n",
    "    h = tf.nn.sigmoid(tf.matmul(X,w_h))\n",
    "    return tf.matmul(h,w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the model\n",
    "model_output= model(X,w_h,w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cost function create apply the softmax on the out put with the given value \n",
    "## it can find the cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = model_output, labels=Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train operation\n",
    "lr = 0.01\n",
    "train_op = tf.train.GradientDescentOptimizer(lr).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ArgMax:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## predict the value of  with argmax\n",
    "tf.arg_max(model_output,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(500):\n",
    "    for start,end in zip(range(len(x_train)),range(len(y_train))):\n",
    "        sess.run(train_op,feed_dict={X:x_train[start:end],Y:y_train[start:end]})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.6543439e-02,  8.7859201e-01, -9.2081124e-01, -1.9668156e+00],\n",
       "       [ 5.6631930e-02,  1.6142329e-03,  8.7726903e-01,  9.8565966e-02],\n",
       "       [ 9.1397661e-01, -8.2624143e-01,  2.1662190e+00, -1.6688812e-01],\n",
       "       [ 2.0642612e+00, -8.4890157e-01,  2.0305133e+00,  6.7134249e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(w_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5654763 , -0.70778275,  0.574048  ],\n",
       "       [-0.39527756,  0.37193772, -0.0313584 ],\n",
       "       [-1.5393908 , -0.5079923 , -2.3383749 ],\n",
       "       [-0.29803067, -1.6216406 , -0.7787286 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(w_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
